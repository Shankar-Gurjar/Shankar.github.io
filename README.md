# Data Scientist
  
## Technical Skills: 
**Languages:** Python, R, SQL, JavaScript, SAS,

**Data Science Tech:** Machine Learning, Deep Learning, Natural Language Processing, data preprocessing, Feature engineering, Linear
regression, Data analysis, Clustering, SVM, Logistic regression, Random Forest, Predictive modeling, Time series forecasting, Data Mining, Statistical Modeling, CI/CD, Airflow, MLOps Frameworks, Cloud-Based Systems, LLM, Transformer (BERT, GPT), data wrangling, ETL, Regular Expression.

**Libraries:** TensorFlow, Keras, PyTorch, Theano, Django, NLTK, ScraPy, Keras, Pandas, NumPy, PySpark, Streamlit.

**Databases:** My-SQL, MongoDB, PostgreSQL, MS-Access.

**Softwares:** Dataiku-DSS, HIVE, Oracle, PyCharm, VS-Code, Google Cloud Platform (GCP), AWS, Azure, Hadoop, Spark, hypothesis testing, regression analysis, A/B Testing, Experimental Design, ETL, JIRA, SAS, Git, Problem-Solving, Teamwork, Communication, Google Analytics, Adobe Analytics, Web analytics, Word, Excel, PowerPoint, Access.

**Data Warehousing:** Visualization Tools: Snowflake, Teradata, Oracle, Amazon Redshift, Cloudera, Alteryx. Tableau, PowerBI, Docker.

**Visualization Tools:** Tableau, PowerBI, Docker.


# Education

M.S., Applied data science | Clarkson University (December 2024)

B.S., Mathematics, Physics |University of Kota (May 2017)

# Work Experience

### Data Scientist @ Cognizant (Aug 2022 - Sep 2023)

• Developed customer segmentation model for insurance client using K-means clustering, improved conversion rate 1.5% & revenue $1.5M annually.

• Developed insurance fraud detection application using random forest & decision tree, resulting in a 60% reduction in fraudulent claims payouts.

• Engineered and optimized ETL processes using AWS Glue, reducing data processing time by 35% and ensuring data accuracy and consistency.

• Automated data workflows using AWS Lambda and Step Functions, increasing operational efficiency & reducing manual intervention by 30%.

• Conducted extensive data analysis & feature engineering to improve model performance, resulting in a 20% increase in prediction accuracy.

• Developed & maintained real-time data pipelines with Amazon Kinesis, enabling instantaneous data processing & analytics for real-time insights.

• Developed interactive dashboards & reporting tools using tableau, communicated insights to stakeholders, facilitating data-driven decision-making.

### AdOps Specialist @ ZYPMedia (Dec 2021 - Aug 2022)

• Developed risk assessment model using decision tree & random forest, resulting in 80% improvement in underwriting accuracy & risk prediction.

• Utilized logistic regression, random forest, & XGBoost, to model complex risk relationships & identify key predictors of insurance claims.

• Developed claim prediction application using k-nearest neighbors & ridge regression, resulting in a 90% increase in claims prediction accuracy.

• Analyzed claims data to identify trends, incorporating features such as policyholder demographics, claim characteristics, & historical claim patterns.

• Engineered robust ETL pipelines using Azure Data Factory, significantly reducing data processing time by 30% & enhancing data quality, integrity.

• Developed predictive models for claim severity estimation, enabling resource allocation & reducing claim settlement time by 50%.

• Implemented scalable data solutions on Azure Synapse Analytics, optimizing query performance by 40% through strategic partitioning & indexing.

• Automated deployment & monitoring of data workflows using Azure DevOps, enhancing CI/CD practices & reducing deployment times by 25%.

• Leveraged Tableau's advanced features such as calculated fields, sets to create dynamic visualizations that effectively communicate key metrics & trends.

### Junior Data Scientist. @ Unique Technomech Pvt. Ltd (Sep 2019 - Nov 2021)

• Engineered dynamic pricing algorithm using regression models, integrated with company website & app, resulting in a 5% increase in revenue.

• Collaborated with actuaries to develop dynamic pricing models, ensuring competitive premiums while maintaining profitability.

• Developed ridge & lasso regression algorithms to optimize pricing strategies, leading to a 20% increase in revenue for insurance products.

• Collaborated with marketing teams to develop personalized marketing strategies for high-churn segments, increasing customer loyalty by 10%.

• Collaborated with the SDE team to integrate ML models into the company's products, improving product functionality and user experience.

• Automated data workflows and orchestrations using GCC (Airflow), enhancing operational efficiency reducing manual processes by 35%.

• Engineered scalable data warehousing solutions on BigQuery, optimizing query performance by 50% through efficient schema design partitioning.

### Data Analyst @ Sygnius Ventures  (Sep 2017 - Sep 2019)

• Developed recommendation systems to cross-sell relevant insurance products, increasing average policyholder lifetime value by 20%.

• Implemented predictive models to forecast the future value of customers, incorporating features such as purchase history, frequency, and monetary value.

• Automated weekly and monthly reports with Power BI, cutting down manual reporting efforts by 50% and ensuring timely data delivery.

• Conducted in-depth analysis using Power BI DAX functions, uncovering key business trends and driving strategic initiatives that boosted revenue by 5%.

• Utilized Python for data cleaning, transformation, and analysis, reducing data processing time by 30% and improving accuracy.

• Provided ad-hoc analysis and insights to support strategic business decisions, leading to a 2% reduction in operational costs.
